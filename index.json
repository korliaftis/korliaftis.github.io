[{"content":"☝️\n","permalink":"https://korliaftis.github.io/posts/diving-into-rust.html","summary":"Everything we have done so far was just setting the stage for our real goal, which is getting our hands dirty with the Rust programming language. It\u0026rsquo;s a modern engineering marvel destined to make all other languages obsolete. Either we jump on the Rust wagon now or get left behind with the memory-unsafe losers.","title":"Diving into Rust"},{"content":"We now have a working system with several tools installed but in most cases we want these tools to work together and reach a specific state before we can start using them. Once we define what that state should look like we also need a simple way to create and tear down environments as needed.\nFor my use case, that state includes a Kubernetes cluster running Traefik, Prometheus and Argo CD. I automate the environment creation process with a Bash script and Terraform.\nTo run the script, you need:\na domain with A records pointing to your system’s local IP address a wildcard TLS certificate a GitHub account with at least one repository your SSH key added to the GitHub account To download the script run the following..\nUSERNAME=\u0026#34;user\u0026#34; curl -Lo /home/${USERNAME}/.scripts/minikube.sh https://blog.korliaftis.com/scripts/minikube.sh chmod +x /home/${USERNAME}/.scripts/minikube.sh Before running the script, make sure to edit it and update the following variables..\nDOMAIN_NAME=\u0026#34;\u0026#34; # your domain name - \u0026#34;domain.xyz\u0026#34; GITHUB_USERNAME=\u0026#34;\u0026#34; # your github username - \u0026#34;user\u0026#34; GITHUB_REPOSITORY=\u0026#34;\u0026#34; # your github repository name - \u0026#34;argocd\u0026#34; MINIKUBE_NODES=\u0026#34;\u0026#34; # the number of minikube nodes - \u0026#34;3\u0026#34; TLS_PUBLIC_KEY_PATH=\u0026#34;\u0026#34; # the full path to the tls public key - \u0026#34;/home/user/.tls/fullchain.cer\u0026#34; TLS_PRIVATE_KEY_PATH=\u0026#34;\u0026#34; # the full path to the tls private key - \u0026#34;/home/user/.tls/domain.xyz.key\u0026#34; SSH_PRIVATE_KEY_PATH=\u0026#34;\u0026#34; # the full path to the ssh private key - \u0026#34;/home/user/.ssh/id_ed25519\u0026#34; In summary, the script first performs a few preflight checks to ensure everything is in order, it then generates Terraform manifests in the ${HOME}/minikube directory and finally applies them in two stages to avoid dependency errors.\nWhen you run the script it will delete all existing Minikube clusters and contents from the ${HOME}/minikube directory.\nIn the following sections we will see more details about some key components.\nminikube We use Minikube with the Docker driver. During installation we created a custom Docker network named minikube allowing the nodes to receive predictable IP addresses.\nThe number of nodes to be created is defined by the MINIKUBE_NODES variable in the script.\nSome of the workloads we deploy require at least 2 nodes otherwise some pods will not be scheduled and remain in a Pending state.\nhaproxy To access HTTP workloads running on Minikube we use the HAProxy we installed on our system.\nIt listens on ports 80 and 443 of the host system and forwards all incoming traffic to the minikube Docker network on ports 31080 and 31443 respectively. For this setup to work, the Kubernetes Ingress Controller (Istio, Traefik, etc) must be configured to create NodePort services on those ports.\nWe have configured HAProxy with active TCP healthchecks so it routes traffic only to backends that have a server running. I have tried some alternatives to HAProxy but none of them could do this simple thing out of the box.. for example NGINX only offers passive TCP healthchecks in it\u0026rsquo;s free version and for active TCP healthchecks we need to use their paid version. I also tried Traefik but as of today it doesn\u0026rsquo;t support any TCP healthchecks for it\u0026rsquo;s backends.\nIn general HAProxy just works, we can access it\u0026rsquo;s dashboard in port 8404 and view it\u0026rsquo;s logs by doing..\nsudo journalctl -u haproxy -f One alternative approach to the whole \u0026ldquo;reverse proxy in front of Minikube\u0026rdquo; thing would be to use MetalLB but I could not make it work consistently with Minikube. That said, it\u0026rsquo;s been some time since I last tested it and it may work great now.\nOne disadvantage of this setup is that ports 80 and 443 of the host system are always bound to HAProxy even when Minikube is not running. If this is something that bothers you, disable the autostart of the HAProxy systemd service and start it only when you need it or even better use a different network interface for HAproxy.\ntraefik As discussed in the HAProxy section, our Ingress Controller needs to use NodePort services on ports 31080 and 3144 so we configure this using the Traefik Helm chart values file.\nAnother thing we configure is a Kubernetes secret on the traefik namespace with the certificate for our domain. Traefik will use this secret to create a TLSStore which will handle TLS for our domain automatically.\nAfter the installation an IngressClass with the name \u0026ldquo;traefik\u0026rdquo; will be created and it will be configured to be the default IngressClass of the cluster. This means that we don\u0026rsquo;t have to set the ingressClassName: field in every Ingress resource we create.\nIf in the future we decide to use multiple Ingress Controllers we can use this field to select which one will handle each Ingress in a case by case basis..\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: # [...] spec: ingressClassName: \u0026#34;traefik\u0026#34; # [...] One final note, Traefik evaluates routing rules based on their length and not based on their \u0026ldquo;specificity\u0026rdquo; meaning that if we create an Ingress for the host blue.domain.xyz and another one for the host *.domain.xyz the rules that will be created will be..\nHost('blue.domain.xyz' HostRegexp('{subdomain:[a-zA-Z0-9-]+}.domain.xyz') The second rule is longer so it will be evaluated first and since it will match the request to blue.domain.xyz it will always take precedence over the more specific route.\nTo solve this we can manually set the priority on the Ingress using an annotation..\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: # [...] annotations: traefik.ingress.kubernetes.io/router.priority: \u0026#34;1\u0026#34; # [...] spec: # [...] The priority can be any value between 1 and 1000 (higher is better). We could either annotate the \u0026ldquo;wildcard\u0026rdquo; Ingress with a low priority or annotate the \u0026ldquo;non-wildcard\u0026rdquo; Ingress with a high priority, either way our problem will be solved.\nprometheus We install 2 Helm charts related to Prometheus, the prometheus-operator-crds and the kube-prometheus-stack.\nWe mostly use default values for both except from the way the Prometheus operator detects ServiceMonitor resources. The default behavior is for Prometheus to scrape a ServiceMonitor only when it has matching labels. This is useful if we have multiple Prometheus operators on the same cluster.\nIn summary the way it works is the following..\nif serviceMonitorSelectorNilUsesHelmValues: false is configured in the values file we need to run kubectl get prometheuses.monitoring.coreos.com -n monitoring -o yaml | grep -A8 serviceMonitorSelector and add the output as labels to our ServiceMonitor if serviceMonitorSelectorNilUsesHelmValues: true is configured in the values file the ServiceMonitor will be scraped automatically In either case the service monitors can be in any namespace.\nAfter the installation we can access Prometheus at https://prometheus.${DOMAIN_NAME} and Alertmanager at https://alertmanager.${DOMAIN_NAME}.\nargo cd We install the argo-cd Helm chart and we just configure ingress related settings through the values file. Additionally we create a Kubernetes secret to store the GitHub account credentials and repository information.\nThe web interface is available at https://argocd.${DOMAIN_NAME}, to login use admin as the username and the output of the following command as the password..\nkubectl get secret -n argocd argocd-initial-admin-secret -o jsonpath=\u0026#34;{.data.password}\u0026#34; | base64 --decode \u0026amp;\u0026amp; echo troubleshooting Usually everything works fine but if there is any issue, start troubleshooting the path of the requests..\nIs DNS pointing to the IP of our system? dig ${DOMAIN_NAME} dig *.${DOMAIN_NAME} Does HAProxy see the backends as online? go with your browser to the IP of your system in port 8404 - http://192.168.1.2:8404 Do the HAProxy logs show our connection attempts? sudo journalctl -u haproxy -f Have all the Helm charts installed correctly? helm list -Aa Are all the pods running? kubectl get pods -A This is not an exhaustive list of everything that could have gone wrong but most likely it\u0026rsquo;s one of these things.\nongoing maintenance To keep everything happy we need to edit the script and keep the following up to date..\nTerraform providers\nkubernetes helm Helm charts\ntraefik traefik-crds kube-prometheus-stack prometheus-operator-crds argo-cd Finally, if you have not automated the process, don\u0026rsquo;t forget to generate a new TLS certificate for your domain every 90 days.\n","permalink":"https://korliaftis.github.io/posts/connecting-the-dots.html","summary":"\u003cp\u003eWe now have a working system with several tools installed but in most cases we want these tools to work together and reach a specific state before we can start using them. Once we define what that state should look like we also need a simple way to create and tear down environments as needed.\u003c/p\u003e\n\u003cp\u003eFor my use case, that state includes a Kubernetes cluster running Traefik, Prometheus and Argo CD. I automate the environment creation process with a Bash script and Terraform.\u003c/p\u003e","title":"Connecting the Dots"},{"content":"Since I started working with computers I always loved the idea of a homelab, a safe space to mess with stuff, break stuff and sometimes learn a few things along the way.\nBack when I was trying to land my first tech job my homelab was a bunch of noisy Cisco switches and routers. Along the way I discovered GNS3 and eventually those physical switches and routers were virtualized on my Sony Vaio VGN-N31Z with it\u0026rsquo;s Core 2 Duo, 2GB of RAM and 120GB of spinning rust.\nA few years later when I started working with Windows my homelab transitioned into a Windows Server 2012 R2 virtual machine running on VirtualBox. It didn’t take long to realize that if I wanted to run more than just a couple of VMs at the same time I would need some serious hardware. So I ended up breaking the bank on a desktop running the free version of VMware ESXi packed with an Intel i7, 64GB of RAM and a bunch of SSDs.\nFast forward again and with everything moving to the public cloud my homelab shifted to an AWS account. What was once a capital expense with finite resources became an operational expense with \u0026ldquo;limitless\u0026rdquo; capabilities.\nThese days my homelab is a vintage Dell Latitude with an Intel i3, 16GB of RAM and a 1TB SSD running Debian. Here is how I set it up..\nFoundation This guide begins after we have selected the hardware, downloaded a Debian 13 ISO, created a bootable USB and completed a minimal installation with only the \u0026ldquo;standard system utilities\u0026rdquo; and \u0026ldquo;SSH server\u0026rdquo; selected.\nBy now we should know our machine’s IP address on the network and have successfully logged in via SSH.\nLet’s get started..\nswitch to the root user..\nsu - set the hostname..\nHOSTNAME=\u0026#34;server\u0026#34; hostnamectl set-hostname ${HOSTNAME} set the timezone..\nTIMEZONE_REGION=\u0026#34;Europe\u0026#34; TIMEZONE_CITY=\u0026#34;Athens\u0026#34; timedatectl set-timezone ${TIMEZONE_REGION}/${TIMEZONE_CITY} install packages..\napt update \u0026amp;\u0026amp; apt upgrade -y apt install -y bash-completion ca-certificates apt-transport-https vim git curl jq gnupg unzip htop tree tmux nmap tcpdump ethtool strace configure sudo..\nUSERNAME=\u0026#34;user\u0026#34; apt install -y sudo usermod -a -G sudo ${USERNAME} enable sudo without password..\nUSERNAME=\u0026#34;user\u0026#34; echo \u0026#34;${USERNAME} ALL=(ALL) NOPASSWD:ALL\u0026#34; | EDITOR=\u0026#39;tee -a\u0026#39; visudo visudo --check configure ssh..\nUSERNAME=\u0026#34;user\u0026#34; install -d -m 0700 -o ${USERNAME} -g ${USERNAME} /home/${USERNAME}/.ssh install -m 0600 -o ${USERNAME} -g ${USERNAME} /dev/null /home/${USERNAME}/.ssh/config install -m 0600 -o ${USERNAME} -g ${USERNAME} /dev/null /home/${USERNAME}/.ssh/authorized_keys su - ${USERNAME} -c \u0026#34;ssh-keygen -t ed25519 -f /home/${USERNAME}/.ssh/id_ed25519 -N \u0026#39;\u0026#39;\u0026#34; sed -i \u0026#39;/^#/! {/AcceptEnv/ s/^/#/}\u0026#39; /etc/ssh/sshd_config enable ssh without password (if the key we use is also configured on GitHub)..\nUSERNAME=\u0026#34;user\u0026#34; GITHUB_USERNAME=\u0026#34;torvalds\u0026#34; curl https://github.com/${GITHUB_USERNAME}.keys \u0026gt;\u0026gt; /home/${USERNAME}/.ssh/authorized_keys set the global git email address for our user account..\nUSERNAME=\u0026#34;user\u0026#34; GITHUB_EMAIL=\u0026#34;torvalds@users.noreply.github.com\u0026#34; su - ${USERNAME} -c \u0026#34;git config --global user.email ${GITHUB_EMAIL}\u0026#34; change the way the bash prompt looks..\nUSERNAME=\u0026#34;user\u0026#34; echo \u0026#39;export PS1=\u0026#34;\\[\\e[37m\\][\\[\\e[93m\\]\\w\\[\\e[37m\\]] \\[\\e[0m\\]\u0026#34;\u0026#39; \u0026gt;\u0026gt; /home/${USERNAME}/.bashrc echo \u0026#39;export PS1=\u0026#34;\\[\\e[37m\\][\\[\\e[91m\\]\\w\\[\\e[37m\\]] \\[\\e[0m\\]\u0026#34;\u0026#39; \u0026gt;\u0026gt; /root/.bashrc create a few files and directories to keep our stuff organized..\nUSERNAME=\u0026#34;user\u0026#34; install -d -m 0775 -o ${USERNAME} -g ${USERNAME} /home/${USERNAME}/.tls install -d -m 0775 -o ${USERNAME} -g ${USERNAME} /home/${USERNAME}/.scripts install -m 0644 -o ${USERNAME} -g ${USERNAME} /dev/null /home/${USERNAME}/.bash_aliases disable the laptop lid function (if we use a laptop)..\necho \u0026#39;HandleLidSwitch=ignore\u0026#39; \u0026gt;\u0026gt; /etc/systemd/logind.conf suppress the output of kernel logs on the console..\necho \u0026#39;kernel.printk = 1 4 1 7\u0026#39; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p increase the /proc/sys/fs/inotify/max_user_instances value..\necho \u0026#39;fs.inotify.max_user_instances = 16384\u0026#39; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p update the password of our user account..\nUSERNAME=\u0026#34;user\u0026#34; passwd ${USERNAME} update the password of the root account..\npasswd root Building Blocks Now that we have established the foundation, we can begin adding our building blocks.\nSince I work as a Site Reliability Engineer the tools I use include the following..\ndocker USERNAME=\u0026#34;user\u0026#34; curl -L https://download.docker.com/linux/debian/gpg | gpg --dearmor \u0026gt; /etc/apt/keyrings/docker.gpg echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;${VERSION_CODENAME}\u0026#34;) stable\u0026#34; \u0026gt; /etc/apt/sources.list.d/docker.list apt update \u0026amp;\u0026amp; apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin usermod -aG docker ${USERNAME} systemctl daemon-reload systemctl enable docker.service systemctl start docker.service By default Docker binds published ports to all interfaces (0.0.0.0) making containers accessible from anywhere. I prefer the opposite, containers should be private unless explicitly exposed.\nsystemctl stop docker.service cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; /etc/docker/daemon.json { \u0026#34;ip\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;metrics-addr\u0026#34;: \u0026#34;0.0.0.0:9323\u0026#34; } EOF systemctl start docker.service kubectl TEMP_DIR=\u0026#34;$(mktemp -d)\u0026#34; curl -Lo ${TEMP_DIR}/kubectl \u0026#34;https://dl.k8s.io/release/$(curl -Ls https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; install -m 0755 -o root -g root ${TEMP_DIR}/kubectl /usr/local/bin/kubectl kubectl completion bash \u0026gt; /etc/bash_completion.d/kubectl k9s TEMP_DIR=\u0026#34;$(mktemp -d)\u0026#34; K9S_VERSION=\u0026#34;$(curl -Ls https://api.github.com/repos/derailed/k9s/releases/latest | jq -r .tag_name)\u0026#34; curl -Lo ${TEMP_DIR}/k9s_Linux_amd64.tar.gz https://github.com/derailed/k9s/releases/download/${K9S_VERSION}/k9s_Linux_amd64.tar.gz tar -xzf ${TEMP_DIR}/k9s_Linux_amd64.tar.gz --directory ${TEMP_DIR} install -m 0755 -o root -g root ${TEMP_DIR}/k9s /usr/local/bin/k9s k9s completion bash \u0026gt; /etc/bash_completion.d/k9s minikube TEMP_DIR=\u0026#34;$(mktemp -d)\u0026#34; curl -Lo ${TEMP_DIR}/minikube_latest_amd64.deb https://storage.googleapis.com/minikube/releases/latest/minikube_latest_amd64.deb dpkg -i ${TEMP_DIR}/minikube_latest_amd64.deb minikube completion bash \u0026gt; /etc/bash_completion.d/minikube When Minikube starts it checks for a Docker network with the same name and creates it automatically if it doesn\u0026rsquo;t exist. By creating this network manually we can define a custom IP range and make the node IPs predictable.\ndocker network rm minikube \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 docker network create \u0026#34;minikube\u0026#34; --driver=\u0026#34;bridge\u0026#34; --subnet=\u0026#34;10.20.30.0/24\u0026#34; --gateway=\u0026#34;10.20.30.1\u0026#34; haproxy A simple reverse proxy to easily access HTTP workloads running on Minikube. It listens on ports 80 and 443 of the system and forwards connections to the Minikube network.\napt install -y haproxy systemctl daemon-reload systemctl enable haproxy.service systemctl stop haproxy.service echo \u0026#39;EXTRAOPTS=\u0026#34;-q\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/default/haproxy cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; /etc/haproxy/haproxy.cfg global log /dev/log local0 info defaults log global timeout client 30000 timeout connect 5000 timeout server 30000 frontend stats mode http bind *:8404 stats enable stats uri / stats refresh 30s no log frontend metrics mode http bind *:8405 http-request use-service prometheus-exporter no log frontend haproxy-http mode tcp bind *:80 default_backend minikube-http option tcplog frontend haproxy-https mode tcp bind *:443 default_backend minikube-https option tcplog backend minikube-http mode tcp server minikube 10.20.30.2:31080 check server minikube-m02 10.20.30.3:31080 check server minikube-m03 10.20.30.4:31080 check server minikube-m04 10.20.30.5:31080 check server minikube-m05 10.20.30.6:31080 check backend minikube-https mode tcp server minikube 10.20.30.2:31443 check server minikube-m02 10.20.30.3:31443 check server minikube-m03 10.20.30.4:31443 check server minikube-m04 10.20.30.5:31443 check server minikube-m05 10.20.30.6:31443 check EOF haproxy -c -f /etc/haproxy/haproxy.cfg systemctl start haproxy.service helm curl -L https://packages.buildkite.com/helm-linux/helm-debian/gpgkey | gpg --dearmor \u0026gt; /etc/apt/keyrings/helm.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/helm.gpg] https://packages.buildkite.com/helm-linux/helm-debian/any any main\u0026#34; \u0026gt; /etc/apt/sources.list.d/helm.list apt update \u0026amp;\u0026amp; apt install -y helm helm completion bash \u0026gt; /etc/bash_completion.d/helm terraform USERNAME=\u0026#34;user\u0026#34; curl -L https://apt.releases.hashicorp.com/gpg | gpg --dearmor \u0026gt; /etc/apt/keyrings/hashicorp.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/hashicorp.gpg] https://apt.releases.hashicorp.com $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;${VERSION_CODENAME}\u0026#34;) main\u0026#34; \u0026gt; /etc/apt/sources.list.d/hashicorp.list apt update \u0026amp;\u0026amp; apt install -y terraform echo \u0026#39;complete -C /usr/bin/terraform terraform\u0026#39; \u0026gt;\u0026gt; /home/${USERNAME}/.bashrc grafana curl -L https://apt.grafana.com/gpg.key | gpg --dearmor \u0026gt; /etc/apt/keyrings/grafana.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/grafana.gpg] https://apt.grafana.com stable main\u0026#34; \u0026gt; /etc/apt/sources.list.d/grafana.list apt update \u0026amp;\u0026amp; apt install -y grafana systemctl daemon-reload systemctl enable grafana-server.service systemctl stop grafana-server.service cp /etc/grafana/grafana.ini /etc/grafana/grafana.ini.bak chown :grafana /etc/grafana/grafana.ini.bak sed -i \u0026#39;s/^;reporting_enabled = true$/reporting_enabled = false/\u0026#39; /etc/grafana/grafana.ini systemctl start grafana-server.service The web interface is on port 3000, login with admin as the username and password.\nact TEMP_DIR=\u0026#34;$(mktemp -d)\u0026#34; ACT_VERSION=\u0026#34;$(curl -Ls https://api.github.com/repos/nektos/act/releases/latest | jq -r .tag_name)\u0026#34; curl -Lo ${TEMP_DIR}/act_Linux_x86_64.tar.gz https://github.com/nektos/act/releases/download/${ACT_VERSION}/act_Linux_x86_64.tar.gz tar -xzf ${TEMP_DIR}/act_Linux_x86_64.tar.gz --directory ${TEMP_DIR} install -m 0755 -o root -g root ${TEMP_DIR}/act /usr/local/bin/act Tactical Enhancements This part of the guide covers things that are nice to have but not strictly necessary.\nA nice upgrade is to register a domain. With a domain we can set up DNS records that take advantage of the global DNS network and also issue valid TLS certificates.\nAfter registering a domain through a registrar, we create a Cloudflare account and transfer the domain\u0026rsquo;s DNS management to it. On Cloudflare, we configure A records that point to the local IP of our system and set up an API key with \u0026ldquo;Edit zone DNS\u0026rdquo; permissions..\ndomain.xyz A 192.168.1.3 *.domain.xyz A 192.168.1.3 With the API key we run a script that uses acme.sh to generate a wildcard TLS certificate and save it to the ~/.ssl directory of our system.\nTo download the script run the following..\nUSERNAME=\u0026#34;user\u0026#34; curl -Lo /home/${USERNAME}/.scripts/acme.sh https://blog.korliaftis.com/scripts/acme.sh chmod +x /home/${USERNAME}/.scripts/acme.sh Before running the script, make sure to edit it and update the following variables..\nUSERNAME=\u0026#34;\u0026#34; # your debian username - \u0026#34;user\u0026#34; DOMAIN_NAME=\u0026#34;\u0026#34; # your domain name - \u0026#34;domain.xyz\u0026#34; CF_ZONE_ID=\u0026#34;\u0026#34; # your cloudflare zone id - \u0026#34;urjukz9cgw1y6ipv35z5hk8bp4f282rz\u0026#34; CF_ACCOUNT_ID=\u0026#34;\u0026#34; # your cloudflare accound id - \u0026#34;rb35t4w3053lofvapz0u2kwq9dwd7p5a\u0026#34; CF_TOKEN=\u0026#34;\u0026#34; # your cloudflare api token - \u0026#34;6_z3K2aFdSpIq6VBkaz3i4xHT_uYiBNmDftWNZ-K\u0026#34; Another useful upgrade to consider is setting up remote access. We could rent a VPS and set up WireGuard tunnels between our devices but this adds latency. A better option is to use something like Nebula where the VPS can act as a broker and not as a relay. Another valid option would be to use Cloudflare tunnels. However, the simplest option is to use a managed service like Tailscale or ZeroTier which can handle everything for us.\nThe last upgrade to consider is configuring wake-on-lan. Most systems support this feature but it must be enabled in both the BIOS and on the network interface. We use ethtool to check if wake-on-lan is enabled on our system\u0026rsquo;s ethernet interface..\nINTERFACE=\u0026#34;\u0026#34; # the name of the ethernet interface - enp2s0 ethtool ${INTERFACE} | grep \u0026#34;Wake-on:\u0026#34; If the output is Wake-on: g it means that wake-on-lan is already enabled, if not we do the following to enable it..\nINTERFACE=\u0026#34;\u0026#34; # the name of the ethernet interface - enp2s0 cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/network/interfaces.d/${INTERFACE} auto ${INTERFACE} iface ${INTERFACE} inet dhcp ethernet-wol g EOF systemctl restart networking.service ethtool ${INTERFACE} | grep \u0026#34;Wake-on:\u0026#34; If we pair wake-on-lan with a Raspberry Pi on the same network and a remote access solution we will be able to power on our system and control it from anywhere.\nOngoing Maintenance Setting things up once is fine but without updates we are stuck with a snapshot of the system from the day it was installed.\nRunning apt update \u0026amp;\u0026amp; apt upgrade -y regularly will keep both the system and most of our tools up to date. To update kubectl, k9s, minikube and act we can simply run their installation commands again.\nThe TLS certificate is valid for 90 days and we can issue a fresh certificate by running the script again.\nClosing Thoughts Allright, we saw a bunch of things and touched many topics but one thing we did not cover is security.\nSo is it secure? Well, we prioritized convenience over security in a few areas but at the end of the day this is a homelab not a production system, it will never store sensitive data and if someone breaks into my house to steal my stuff my crusty old hardware will be the least of my concerns.\nAt the end of the day this is all about experimentation and learning so take what works for you and make it your own.\n","permalink":"https://korliaftis.github.io/posts/laying-the-foundation.html","summary":"\u003cp\u003eSince I started working with computers I always loved the idea of a homelab, a safe space to mess with stuff, break stuff and sometimes learn a few things along the way.\u003c/p\u003e\n\u003cp\u003eBack when I was trying to land my first tech job my homelab was a bunch of noisy Cisco switches and routers. Along the way I discovered GNS3 and eventually those physical switches and routers were virtualized on my Sony Vaio VGN-N31Z with it\u0026rsquo;s Core 2 Duo, 2GB of RAM and 120GB of spinning rust.\u003c/p\u003e","title":"Laying the Foundation"}]